{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025c3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc2a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0866bd",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c83a535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>7e66ca1a42</td>\n",
       "      <td>but you always have lee. Let`s go to Paris</td>\n",
       "      <td>but you always have lee. Let`s go to Paris</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>fd987ed435</td>\n",
       "      <td>Surgery.</td>\n",
       "      <td>Surgery.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>f6f69e5073</td>\n",
       "      <td>RIP Michael</td>\n",
       "      <td>RIP Michael</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>5a345a2602</td>\n",
       "      <td>Adem in, adem uit</td>\n",
       "      <td>Adem in, adem uit</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21430</th>\n",
       "      <td>a92db139c6</td>\n",
       "      <td>one of them is</td>\n",
       "      <td>one of them is</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16634</th>\n",
       "      <td>64c8534abc</td>\n",
       "      <td>Feel sorry for Adam Cook. Be strong for David and family</td>\n",
       "      <td>sorry</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18921</th>\n",
       "      <td>173b6b6ee3</td>\n",
       "      <td>at the store! Lol I don`t have any liquour here</td>\n",
       "      <td>at the store! Lol I don`t have any liquour here</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>32f4183741</td>\n",
       "      <td>Horrid dream. I suspect I will have to cancel my plans tonight...</td>\n",
       "      <td>Horrid dream.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>b924039252</td>\n",
       "      <td>my sister is a douchebag</td>\n",
       "      <td>douchebag</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>9dd013a94b</td>\n",
       "      <td>will have to wait on the recipe at Simply Recipes.  Sorries!</td>\n",
       "      <td>.  Sorrie</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID  \\\n",
       "462    7e66ca1a42   \n",
       "15775  fd987ed435   \n",
       "24340  f6f69e5073   \n",
       "2475   5a345a2602   \n",
       "21430  a92db139c6   \n",
       "16634  64c8534abc   \n",
       "18921  173b6b6ee3   \n",
       "17996  32f4183741   \n",
       "4930   b924039252   \n",
       "5560   9dd013a94b   \n",
       "\n",
       "                                                                    text  \\\n",
       "462                           but you always have lee. Let`s go to Paris   \n",
       "15775                                                           Surgery.   \n",
       "24340                                                        RIP Michael   \n",
       "2475                                                   Adem in, adem uit   \n",
       "21430                                                     one of them is   \n",
       "16634           Feel sorry for Adam Cook. Be strong for David and family   \n",
       "18921                    at the store! Lol I don`t have any liquour here   \n",
       "17996  Horrid dream. I suspect I will have to cancel my plans tonight...   \n",
       "4930                                            my sister is a douchebag   \n",
       "5560        will have to wait on the recipe at Simply Recipes.  Sorries!   \n",
       "\n",
       "                                         selected_text sentiment  \n",
       "462         but you always have lee. Let`s go to Paris   neutral  \n",
       "15775                                         Surgery.   neutral  \n",
       "24340                                      RIP Michael  negative  \n",
       "2475                                 Adem in, adem uit   neutral  \n",
       "21430                                   one of them is   neutral  \n",
       "16634                                            sorry  negative  \n",
       "18921  at the store! Lol I don`t have any liquour here   neutral  \n",
       "17996                                    Horrid dream.  negative  \n",
       "4930                                         douchebag  negative  \n",
       "5560                                         .  Sorrie  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load file\n",
    "df = pd.read_csv('../data/Tweets.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774449b",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106e2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    if text is not None and isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "        # Remove usernames starting with '@'\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "        # Remove hashtags starting with '#'\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "\n",
    "        # Remove non-alphabetic characters\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "        # Lemmatize words\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "        # Remove words with 3 characters or less\n",
    "        text = ' '.join([word for word in text.split() if len(word) > 3])\n",
    "\n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "        # Remove duplicate words while preserving the order\n",
    "        words = text.split()\n",
    "        text = ' '.join(list(dict.fromkeys(words)))\n",
    "\n",
    "    else:\n",
    "        text = ''\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccc8ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>having my hair dyed today  ugh im bored. still tired from friday lol. swear down bossman ;)</td>\n",
       "      <td>hair dyed today bored still tired friday swear bossman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10936</th>\n",
       "      <td>Going to workout + swin... fun</td>\n",
       "      <td>going workout swin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17969</th>\n",
       "      <td>Burp the Frog  http://is.gd/rae9</td>\n",
       "      <td>burp frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22393</th>\n",
       "      <td>I do the same thing to anybody covering dave... haha... we don`t like people messing with perfect music.</td>\n",
       "      <td>thing anybody covering dave haha like people messing perfect music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Nyappy mother`s day to your mom`s.</td>\n",
       "      <td>nyappy mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12332</th>\n",
       "      <td>on myyearbook, myspace, here and messenger</td>\n",
       "      <td>myyearbook myspace messenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19573</th>\n",
       "      <td>No, it`s people you are recommending that others follow, like followfriday, only with pics!</td>\n",
       "      <td>people recommending others follow like followfriday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26796</th>\n",
       "      <td>horseback riding</td>\n",
       "      <td>horseback riding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22060</th>\n",
       "      <td>jerk josh! didn`t even come meet me  - im thinking of a number guess ?</td>\n",
       "      <td>jerk josh even come meet thinking number guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>Loads of Beard papas have disappeared in the UK too</td>\n",
       "      <td>load beard papa disappeared</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             text  \\\n",
       "9908                  having my hair dyed today  ugh im bored. still tired from friday lol. swear down bossman ;)   \n",
       "10936                                                                              Going to workout + swin... fun   \n",
       "17969                                                                            Burp the Frog  http://is.gd/rae9   \n",
       "22393    I do the same thing to anybody covering dave... haha... we don`t like people messing with perfect music.   \n",
       "509                                                                            Nyappy mother`s day to your mom`s.   \n",
       "12332                                                                  on myyearbook, myspace, here and messenger   \n",
       "19573                 No, it`s people you are recommending that others follow, like followfriday, only with pics!   \n",
       "26796                                                                                            horseback riding   \n",
       "22060                                      jerk josh! didn`t even come meet me  - im thinking of a number guess ?   \n",
       "19976                                                         Loads of Beard papas have disappeared in the UK too   \n",
       "\n",
       "                                                               clean_text  \n",
       "9908               hair dyed today bored still tired friday swear bossman  \n",
       "10936                                                  going workout swin  \n",
       "17969                                                           burp frog  \n",
       "22393  thing anybody covering dave haha like people messing perfect music  \n",
       "509                                                         nyappy mother  \n",
       "12332                                        myyearbook myspace messenger  \n",
       "19573                 people recommending others follow like followfriday  \n",
       "26796                                                    horseback riding  \n",
       "22060                      jerk josh even come meet thinking number guess  \n",
       "19976                                         load beard papa disappeared  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the clean_text function to the 'raw_sentence' column of the dataframe\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "df[['text', 'clean_text']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3682fd",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ca692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15569</th>\n",
       "      <td>thought wallace gromit team behind monkey island could combined disastrously</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>Moderately Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>wish school year would faster move life</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>always pretty athletic especially love ball anyway yeah</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820</th>\n",
       "      <td>suck went jail couldnt tweet anymore</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>Moderately Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>ummm didnt work guess stuck uglyonee</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9902</th>\n",
       "      <td>updating live benihana tokyo waikiki happy birthday mark</td>\n",
       "      <td>0.47</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>sure hope becomes afternoon</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>finally shifted twhirl tweetdeck filter close friend update happy monday peep</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Moderately Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14458</th>\n",
       "      <td>girl aidan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16903</th>\n",
       "      <td>reading book sunshine goona good</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          clean_text  \\\n",
       "15569   thought wallace gromit team behind monkey island could combined disastrously   \n",
       "5078                                         wish school year would faster move life   \n",
       "1527                         always pretty athletic especially love ball anyway yeah   \n",
       "12820                                           suck went jail couldnt tweet anymore   \n",
       "4552                                            ummm didnt work guess stuck uglyonee   \n",
       "9902                        updating live benihana tokyo waikiki happy birthday mark   \n",
       "413                                                      sure hope becomes afternoon   \n",
       "2040   finally shifted twhirl tweetdeck filter close friend update happy monday peep   \n",
       "14458                                                                     girl aidan   \n",
       "16903                                               reading book sunshine goona good   \n",
       "\n",
       "       textblob_polarity   sentiment_textblob  \n",
       "15569              -0.38  Moderately Negative  \n",
       "5078                0.00              Neutral  \n",
       "1527                0.62             Positive  \n",
       "12820              -0.10  Moderately Negative  \n",
       "4552                0.00              Neutral  \n",
       "9902                0.47  Moderately Positive  \n",
       "413                 0.50             Positive  \n",
       "2040                0.40  Moderately Positive  \n",
       "14458               0.00              Neutral  \n",
       "16903               0.70             Positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to get the sentiment polarity score\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply the function to the 'clean_text' column and round the result to 2 decimal places\n",
    "df['textblob_polarity'] = df['clean_text'].apply(get_sentiment).round(2)\n",
    "\n",
    "# Define a function to categorize the sentiment polarity score into 4 categories\n",
    "def categorize_sentiment(score):\n",
    "    if score >= 0.5:\n",
    "        return 'Positive'\n",
    "    elif score >= 0.05 and score < 0.5:\n",
    "        return 'Moderately Positive'\n",
    "    elif score > -0.05 and score < 0.05:\n",
    "        return 'Neutral'\n",
    "    elif score > -0.5 and score <= -0.05:\n",
    "        return 'Moderately Negative'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "# Apply the categorize_sentiment function to the 'textblob_polarity' column\n",
    "df['sentiment_textblob'] = df['textblob_polarity'].apply(categorize_sentiment)\n",
    "\n",
    "# Select the relevant columns for display\n",
    "df[['clean_text', 'textblob_polarity', 'sentiment_textblob']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161d9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2915276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27480 entries, 0 to 27480\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   textID              27480 non-null  object \n",
      " 1   text                27480 non-null  object \n",
      " 2   selected_text       27480 non-null  object \n",
      " 3   sentiment           27480 non-null  object \n",
      " 4   clean_text          27480 non-null  object \n",
      " 5   textblob_polarity   27480 non-null  float64\n",
      " 6   sentiment_textblob  27480 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f52887b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral                12071\n",
       "Moderately Positive     6594\n",
       "Positive                4433\n",
       "Moderately Negative     2923\n",
       "Negative                1459\n",
       "Name: sentiment_textblob, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_counts = df['sentiment_textblob'].value_counts()\n",
    "sentiment_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c85f9b",
   "metadata": {},
   "source": [
    "# Balancing Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de697de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral                12071\n",
      "Positive               12071\n",
      "Moderately Positive    12071\n",
      "Negative               12071\n",
      "Moderately Negative    12071\n",
      "Name: sentiment_textblob, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Extract the sentiment labels and features from your DataFrame\n",
    "labels = df['sentiment_textblob']\n",
    "features = df['clean_text']\n",
    "\n",
    "# Create an instance of the RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply the oversampling to balance the classes\n",
    "features_balanced, labels_balanced = oversampler.fit_resample(features.values.reshape(-1, 1), labels)\n",
    "\n",
    "# Convert the balanced features and labels back to a DataFrame\n",
    "balanced_df = pd.DataFrame({'clean_text': features_balanced.flatten(), 'sentiment_textblob': labels_balanced})\n",
    "\n",
    "# Display the balanced sentiment counts\n",
    "balanced_sentiment_counts = balanced_df['sentiment_textblob'].value_counts()\n",
    "print(balanced_sentiment_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b848ec7",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013f4169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aaaa  aaaa cant  aaaa need  aaaaaaaaaaa  aaaaaaaaaaa mcfly  \\\n",
      "0   0.0        0.0        0.0          0.0                0.0   \n",
      "1   0.0        0.0        0.0          0.0                0.0   \n",
      "2   0.0        0.0        0.0          0.0                0.0   \n",
      "3   0.0        0.0        0.0          0.0                0.0   \n",
      "4   0.0        0.0        0.0          0.0                0.0   \n",
      "\n",
      "   aaaaaaaaaahhhhhhhh  aaaaaaaaaahhhhhhhh gonna  aaaaaaaaaamazing  \\\n",
      "0                 0.0                       0.0               0.0   \n",
      "1                 0.0                       0.0               0.0   \n",
      "2                 0.0                       0.0               0.0   \n",
      "3                 0.0                       0.0               0.0   \n",
      "4                 0.0                       0.0               0.0   \n",
      "\n",
      "   aaaaaaaaaamazing trip  aaaaaaaafternoon  ...  zyrtec sleep  zzzz  \\\n",
      "0                    0.0               0.0  ...           0.0   0.0   \n",
      "1                    0.0               0.0  ...           0.0   0.0   \n",
      "2                    0.0               0.0  ...           0.0   0.0   \n",
      "3                    0.0               0.0  ...           0.0   0.0   \n",
      "4                    0.0               0.0  ...           0.0   0.0   \n",
      "\n",
      "   zzzz taking  zzzzy  zzzzy office  zzzzzzz  zzzzzzz goodnight  \\\n",
      "0          0.0    0.0           0.0      0.0                0.0   \n",
      "1          0.0    0.0           0.0      0.0                0.0   \n",
      "2          0.0    0.0           0.0      0.0                0.0   \n",
      "3          0.0    0.0           0.0      0.0                0.0   \n",
      "4          0.0    0.0           0.0      0.0                0.0   \n",
      "\n",
      "   zzzzzzzzzzzzzzz  zzzzzzzzzzzzzzz boring  sentiment_textblob  \n",
      "0              0.0                     0.0             Neutral  \n",
      "1              0.0                     0.0             Neutral  \n",
      "2              0.0                     0.0             Neutral  \n",
      "3              0.0                     0.0             Neutral  \n",
      "4              0.0                     0.0             Neutral  \n",
      "\n",
      "[5 rows x 116931 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "# Assuming your balanced DataFrame is named 'balanced_df'\n",
    "# Extract the balanced features and labels\n",
    "features = balanced_df['clean_text']\n",
    "labels = balanced_df['sentiment_textblob']\n",
    "\n",
    "# Create an instance of the TfidfVectorizer with n-grams\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the features\n",
    "features_transformed = vectorizer.fit_transform(features)\n",
    "\n",
    "# Convert the transformed features to a sparse matrix\n",
    "features_sparse = csr_matrix(features_transformed)\n",
    "\n",
    "# Create a DataFrame from the sparse matrix\n",
    "features_df = pd.DataFrame.sparse.from_spmatrix(features_sparse, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the features DataFrame with the labels\n",
    "data = pd.concat([features_df, labels], axis=1)\n",
    "\n",
    "# Display the data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750987b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cccab70",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24123fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape: (48284, 116930)\n",
      "Train Labels Shape: (48284,)\n",
      "Test Features Shape: (12071, 116930)\n",
      "Test Labels Shape: (12071,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your data is stored in the 'data' DataFrame\n",
    "# Extract the features and labels\n",
    "features = data.drop('sentiment_textblob', axis=1)  # Assuming the features are stored in columns other than the sentiment column\n",
    "labels = data['sentiment_textblob']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the split datasets\n",
    "print(\"Train Features Shape:\", train_features.shape)\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Test Features Shape:\", test_features.shape)\n",
    "print(\"Test Labels Shape:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f304d",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c13d2862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Moderately Negative       0.86      0.98      0.92      2493\n",
      "Moderately Positive       0.87      0.88      0.87      2436\n",
      "           Negative       0.85      1.00      0.92      2356\n",
      "            Neutral       0.96      0.52      0.67      2368\n",
      "           Positive       0.87      0.97      0.91      2418\n",
      "\n",
      "           accuracy                           0.87     12071\n",
      "          macro avg       0.88      0.87      0.86     12071\n",
      "       weighted avg       0.88      0.87      0.86     12071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create an instance of the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier using the training data\n",
    "nb_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = nb_classifier.predict(test_features)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47216077",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e17efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create an instance of the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier using the training data\n",
    "nb_classifier.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25216bf",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8c771ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Moderately Negative       0.86      0.98      0.92      2493\n",
      "Moderately Positive       0.87      0.88      0.87      2436\n",
      "           Negative       0.85      1.00      0.92      2356\n",
      "            Neutral       0.96      0.52      0.67      2368\n",
      "           Positive       0.87      0.97      0.91      2418\n",
      "\n",
      "           accuracy                           0.87     12071\n",
      "          macro avg       0.88      0.87      0.86     12071\n",
      "       weighted avg       0.88      0.87      0.86     12071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = nb_classifier.predict(test_features)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f4a43",
   "metadata": {},
   "source": [
    "# Fine-tuning and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d614d1",
   "metadata": {},
   "source": [
    "1. Hyperparameter Tuning\n",
    "2. Feature Engineering\n",
    "3. Model Selection\n",
    "4. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ce3f9",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7506020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocess the features of the new data\n",
    "new_data = \"this is my first time to make sentiment analyzer\"\n",
    "new_data_features = vectorizer.transform([new_data])\n",
    "\n",
    "# Make predictions on the preprocessed features using the trained model\n",
    "predictions = nb_classifier.predict(new_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ad67229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Moderately Positive'], dtype='<U19')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f830d",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5af7d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "with open('naive_bayes_model.pkl', 'wb') as file:\n",
    "    pickle.dump(nb_classifier, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c4ef1",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e049608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text for sentiment prediction: hello\n",
      "Your sentence: hello\n",
      "Predicted sentiment: ['Neutral']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved model\n",
    "with open('naive_bayes_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Get user input for the text\n",
    "new_sentence = input(\"Enter the text for sentiment prediction: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "cleaned_sentence = clean_text(new_sentence)\n",
    "\n",
    "# Vectorize the preprocessed sentence\n",
    "new_sentence_features = vectorizer.transform([cleaned_sentence])\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(new_sentence_features)\n",
    "\n",
    "# Print the user input and predicted sentiment\n",
    "print(\"Your sentence:\", new_sentence)\n",
    "print(\"Predicted sentiment:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f01d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
